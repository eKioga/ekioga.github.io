<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xsl" href="atom.xsl"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://ekioga.github.io/docusaurus-blog/blog</id>
    <title>Things I say Blog</title>
    <updated>2025-10-13T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://ekioga.github.io/docusaurus-blog/blog"/>
    <subtitle>Things I say Blog</subtitle>
    <icon>https://ekioga.github.io/docusaurus-blog/img/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[Toe buttons and Home Assistant. Am I the only one doing this?]]></title>
        <id>https://ekioga.github.io/docusaurus-blog/blog/toe-buttons-and-home-assistant-am-i-the-only-one-doing-this</id>
        <link href="https://ekioga.github.io/docusaurus-blog/blog/toe-buttons-and-home-assistant-am-i-the-only-one-doing-this"/>
        <updated>2025-10-13T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[I've relied on Alexa for many years. It turns my TV on and off with my voice because I like to eat my pizza with a slice in each hand. I wouldn't have time to get anything done without it.]]></summary>
        <content type="html"><![CDATA[<p>I've relied on Alexa for many years. It turns my TV on and off with my voice because I like to eat my pizza with a slice in each hand. I wouldn't have time to get anything done without it.</p>
<p>It lives inside an old fire TV cube, muted with no HDMI plugged in for over 6 years. Every time I told it to turn the TV on or off, it did. It served no other purpose.</p>
<p>Earlier this year, I finally got around to setting up home assistant after learning about ZigBee devices (more on that in&nbsp;<a href="https://eric-post.com/my-home-network/" target="_blank" rel="noopener noreferrer" class="">my network</a>&nbsp;post). That gave me the push I needed to give this project a shot.</p>
<p>Stuff I bought:</p>
<ul>
<li class="">Raspberry Pi 5 8GB</li>
<li class="">KLIM Talk USB Desk Microphone<!-- -->
<ul>
<li class="">KISEER 2 Pcs USB 2.0 Mini Microphone (backup Mics)</li>
</ul>
</li>
<li class="">LIELONGREN USB Computer Speaker</li>
<li class="">Tuya Smart IR Blaster<!-- -->
<ul>
<li class="">Lets Home Assistant record and send IR blast on command. This is how I manage my TV inputs.</li>
</ul>
</li>
<li class="">SONOFF Zigbee Indoor Temperature Humidity Sensor<!-- -->
<ul>
<li class="">I had hopes of setting this up to kick-off my dehumidifier, but I lost the remote, so I haven't had a chance to record the IR code.</li>
</ul>
</li>
<li class="">SONOFF Zigbee Smart Plug</li>
<li class="">Aqara LED Strip T1</li>
<li class="">THIRDREALITY ZigBee Smart Button 3 Pack<!-- -->
<ul>
<li class="">More on this near the bottom.</li>
</ul>
</li>
</ul>
<p>Setup was pretty simple. Though, it did take some time fussing over the hardware and software components getting them all to work together in sync. Eventually, I was up and running with my own voice assistant that responded to "Hey, Randy". (My wife liked the idea of our in-house AI having the voice of Randy Marsh from South Park.) I had it connected it to my local AI server running Ollama, Faster-Whisper (nvidia) and Piper (nvidia). In addition to the normal run-of-the-mill home automation tasks, Randy could also answer general questions using local LLMs! Pretty cool.</p>
<p>After a few days of things working well enough, Alexa was turned off and tossed in a drawer. Good by forever.</p>
<p>Here's the rub. Every other day, something unique and bizarre would break with some aspect of the voice assistant chain.</p>
<ul>
<li class="">Some days the USB mic had to be unplugged and plugged back in.</li>
<li class="">Some days I had to disable the mic within home assistance's hardware settings, then re-enable it to get it to work.</li>
<li class="">Some days the ZigBee network running on home assistant would inexplicably crash in a way that home assistant couldn't detect as a 'down' state.</li>
<li class="">Some days either piper or whisper would inexplicably break. Requiring the services to be 'rebooted' on the server.</li>
<li class="">Some days, telling it to turn on/off the TV would illicit bizarre and lengthy responses that can't be interrupted. I'd mute the speaker and move on with my day.</li>
<li class="">If you need to reboot the Raspberry Pi it's running on, then you will be going through the list above (and more) struggling to get it to work again.</li>
<li class="">Even worse, on some days, none of the above would resolve the issue. I would then give up, make zero changes and come back a few days or week later and suddenly everything is working great. The next day, it's broken again. Two days later, suddenly works great. Yucky.</li>
</ul>
<p>It felt like Randy had a hard time getting out of bed sometimes. Come back later and try again would eventually replace my troubleshooting steps.</p>
<p>My Alexa sat in a dark cabinet with only power for over half a decade and it always just 'worked'. This open source voice assistant from home assistant is janky at best. I get it. It's using a stack of random hardware and software cobbled together in a long daisy chain just to get something that feels similar to Alexa and Google home. I'm not surprised that I had some issues, but this just has one job: Turn the TV on/off. Having it randomly fail at this task every other day, for random reasons, leading to lengthy troubleshooting, wore thin on me really quickly. I don't want to bring back the privacy nightmare (Alexa), so what do I do?</p>
<p>Bought toe buttons. Connected them to my ZigBee network. Assigned TV/OFF IR blast on the long press. Tossed toe button on the floor next to the TV. Works flawlessly. Once again, I can hold a pizza slice in each hand while turning the TV on and off.</p>
<p>In this configuration, the only problem I run into is the occasional ZigBee network crash a few times a month. That is fixed in just a minute. I still have the voice-assistant setup and the AI components still running pointlessly. I haven't felt the need to care about them in months. Speaker is mute. Just toe buttons from now on.</p>
<p>I recommend that everybody move over to toe buttons.</p>]]></content>
        <author>
            <name>Eric Post</name>
            <uri>https://linkedin.com/in/erickpost</uri>
        </author>
        <category label="Self-Hosting" term="Self-Hosting"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[My Hardware & How it Has Evolved]]></title>
        <id>https://ekioga.github.io/docusaurus-blog/blog/my-hardware-how-it-has-evolved</id>
        <link href="https://ekioga.github.io/docusaurus-blog/blog/my-hardware-how-it-has-evolved"/>
        <updated>2025-10-03T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Up until around 2008, I would be either hosting a Ventrillo server or some ad-hoc game server directly off my gaming rig. Before I learned about port-forwarding, I'd route the ethernet cable from the ISP modem directly into my desktop computer so all my friends can connect over. I'm not going to let some firewall tell me what I can and can't host! I was a dumb kid that reformatted his system almost weekly back then. I wonder why...]]></summary>
        <content type="html"><![CDATA[<p>Up until around 2008, I would be either hosting a Ventrillo server or some ad-hoc game server directly off my gaming rig. Before I learned about port-forwarding, I'd route the ethernet cable from the ISP modem directly into my desktop computer so all my friends can connect over. I'm not going to let some firewall tell me what I can and can't host! I was a dumb kid that reformatted his system almost weekly back then. I wonder why...</p>
<p>From 2008 to 2014, my self-hosting skills got a bit better. I had a spare MacBook Pro that I would run Ubuntu on. I guess this would be my first server hardware. As a bonus, I knew enough about networking that I had zero problems managing proper firewall access. I'd host my ventrillo and game servers strait from the local terminal. It's built in battery acting like a UPS. I felt like a wizard. That is, until the MacBook would over-heat each time I tried to shut the lid or place it somewhere out of the way. Not great, but I got by.</p>
<p>In 2015, two big things happened. I was introduced to Raspbery Pi's through a work project. I was also gifted an old Dell PowerEdge desktop server from 2012 by my IT director.</p>
<p>My IT director at the time had a dream where we would stick a Raspberry Pi to the back of the TV in the IT room. He wanted it to display up/down checks to all the satellite offices spread out across the US. Mostly as a display prop for when upper management walks in.</p>
<p>I told him that if bought the Raspberry Pi 3, I'd work on making his dream a reality. I was just a helpdesk guy who never used one or seen one before, but the idea of tinkering with it and learning more while getting paid was too hard to pass up. Within a few days, I had the Raspberry Pi 3 stuck on the back of the TV, running Raspbian desktop as the OS, with CheckMK running network checks under the hood. It looked nice with the CheckMK browser dashboard up on full screen. I felt some pride.</p>
<p>My director was happy, and I got to learn a lot about using a Raspberry Pi, Linux and networking tools like Nagios, Cacti and CheckMK. I was so happy with what I learned that I went home and bought 4x Raspberry Pi's for my home lab and a tiny cluster rack to store them in. Each Pi ran headless Raspbian OS, hosted its own service and remotely managed over SSH. I installed Pihole on one of these Pi's and pointed my network equipment at it as my DNS server. (This was my internal DNS server all the way until mid-way 2025 where I migrated over to AdguardHome due to its DNSSEC features that PiHole didn't have.) It ran almost constantly for 9 years with zero issues. Same with my other Pi's. I trust them.</p>
<p>The Dell PowerEdge desktop server introduced my home to server VMs. It had fancy ECC ram and a Xeon processor. It felt like the real deal to me at the time. I had already played with ESXi a lot already on an old company test server. (That is where I'd validate all my ideas.) So, naturally, I installed ESXi on my new test server at home. Learning about importing&nbsp;<a href="https://www.turnkeylinux.org/?ref=eric-post.com" target="_blank" rel="noopener noreferrer" class="">TurnKey Linux</a>&nbsp;VMs took my addiction to another level. After a month or two, I started testing other hypervisors and then settled on ProxMox, my favorite hypervisor to this day.</p>
<p>I ran this desktop server with several VMs for 8 years. Over the duration, its performance became agonizingly slow with it's 10 year old hard drives. I knew I needed to come up with another hardware solution soon, but I dragged my feet as much as I could.</p>
<p>It was around then that I finally explored this whole 'container' stuff. I've dabbled in docker and Kubernetes years before, I'd get stuff working, but it never really clicked why I'd want to it over VMs. I'd shut it all down and move back to VMs. Turns out, I had been doing it the hard way.</p>
<p>One day in 2022, while looking up documentation on how to install a shiny new service to a VM I had set up, I saw mention of something called "Docker Compose". I've seen this phrase pop up more and more over the years and decided to look into it. After a few hours of learning and testing, I was done with VMs forever. I now hate them. Docker compose all the things! So what now?</p>
<p>Consolidate my entire home lab into one single device!</p>
<p>My new plan was simple. Purchase a Synology NAS with the beefiest CPU, throw 32 GB of RAM. I then popped in 2 TB of NVME storage and 8TB of HD storage into it. NVME for server workloads and HD for data storage. I felt like the smartest guy around thinking I can consolidate everything into one device I can just hide.</p>
<p>The parts came, I put it all together and realized 3 awful things.</p>
<ul>
<li class="">Synology now only accepts Synology branded NVME hard drives. I ran into this problem after installing my 2TB WD NVME reds. I quickly found a workaround online that disabled this check and my WD reds ran without an issue since. However, there is always the fear with any given update that those 2x WD reds might drop off the file system because they are not "official" drives. Luckily, that never happened.</li>
<li class="">Synology wants you to pay a monthly subscription if you dare to run more than 2 VMs at the same time. I had no idea. Suddenly the 32GB of ram I invested felt pretty dumb now.</li>
<li class="">Synology's container manager does work with docker compose, but its interface is limited and makes some odd choices. What's even worse is that it's always running a two-year-old version of docker under the hood. Since every docker version that is over a year old is end-of-life, every Synology update to the container manager is archeological on arrival. I really hate that.</li>
</ul>
<p>I went from Synology being by far my favorite hardware for running a NAS to something I will never purchase again. I don't want to buy products that explode out into required subscriptions when you want to use its features. I really wish I did my homework on this one instead of making assumptions.</p>
<p>What now? Repeat what I did 10 years earlier. Freak out and buy 4x Raspberry Pi 5 devices and dump my containers onto those. I get to have full control again I learned about Portainer and used that in conjunction with Gitea (where I stored my docker compose files) to remotely start/stop and deploy docker compose workloads across any device with docker installed. Even easier and more addicting than TurnKey Linux.</p>
<p>After using them in multiple configurations, including a Docker Swarm setup across all 4 pi's that included features like HA (keepalived) and replication (CephOS). That worked alright, but the setup was way too complicated for running a few containers. I think I used 0.2% of the resources of just one of these Pis. So, I broke apart my cluster and moved on. I settled on running each Pi as its own container server while keeping the exposed volumes on an NFS share hosted on my NAS. This honestly worked really well, and I could coasted on this forever. I liked being able to deploy a docker compose file on any server without having to worry about losing data.</p>
<p>I don't regret buying those RPi5 devices. I did for a while back when I was only using one for my container workloads. Now days, I have one running home assistant OS, one at my Mom's house running a tale scale router so I can give her access to my picture hosting service (built in Raspberry Pi connect service makes this a dream to use as a jump box). I have one that runs bare-metal services that aren't available/compatible as a container. I have a spare one that I use for testing from time to time. It was running CasaOS for a while, but that was not a good solution for me.</p>
<p>Even though my dreams of running an all-in-one home lab shattered with Synology, there still is hope. I learned about Unraid and after a few weeks of testing that, I bought a lifetime license. It's running on my 5-year-old gaming rig. It's proven to be everything I could want and more. As the years go on, I will be migrating more and more stuff over to it until it's the only running box in my house. Any container workloads that don't play nice in Unraid's native interface gets relegated to a padded cell (a container VM) just for them, also running on Unraid. That's been working very nice for me over the last 4 months.</p>
<p>Okay, enough of all that, here is the hardware I am running today.</p>
<ul>
<li class="">2x Synology NAS.<!-- -->
<ul>
<li class="">The old one runs media related stuff because it has a celeron chip. Slow as heck, but it does well with video transcoding.</li>
<li class="">The new one just holds data, NFS work loads and run just one service, Syncthing. I think of it as my datacenter. As in, the center of my data.<!-- -->
<ul>
<li class="">I'll admit that I've had to run some VMs on it in emergency situations. Even though It's limited to 2 running VMs, this has been very helpful in a pinch. As in, I broke something that I don't remember how to fix. Been very handy to get something going as a workaround while I fix the actual issue.</li>
</ul>
</li>
</ul>
</li>
<li class="">4x Rasperry Pi 5<!-- -->
<ul>
<li class="">Pi #1: Home Assistant OS<!-- -->
<ul>
<li class="">Runs container workloads.<!-- -->
<ul>
<li class="">Primary DNS server.</li>
</ul>
</li>
</ul>
</li>
<li class="">Pi #2: Bare metal app server</li>
<li class="">Pi #3: Tail scale router at a remote location</li>
<li class="">Pi #4: Off and doing nothing.</li>
</ul>
</li>
<li class="">4x Raspberry Pi 3 (still kicking after 10 years)<!-- -->
<ul>
<li class="">Pi #1: Secondary DNS server (automatically syncs with primary DNS server)</li>
<li class="">Pi #2: Ansible server</li>
<li class="">Pi #3: Off and Unused</li>
<li class="">Pi #4: Power cable died. Not motivated to replace it.</li>
</ul>
</li>
<li class="">Gaming Desktop PC (I7, 32GB Ram, 2TB of NVME storage and an NVIDIA 2080 super for simple AI workloads)<!-- -->
<ul>
<li class="">My beloved Unraid server.<!-- -->
<ul>
<li class="">Runs container and VM workloads.</li>
</ul>
</li>
</ul>
</li>
<li class="">Bonus: 2x gaming PCs (AMD Ryzen 7 9800XD and NVIDIA 4080 super)<!-- -->
<ul>
<li class="">Only included because I have them connected to my LLM proxy to run advanced local AI workloads on. They just have better video cards than my "AI" server right now. So, I guess I need to include them as servers.</li>
</ul>
</li>
</ul>
<p>What have I learned?</p>
<ul>
<li class="">Just because a service runs on a container, doesn't mean it will work well with the hardware you are running it on. Example: Some containers are not ARM compatible, therefore cannot run on a Pi.</li>
<li class="">Some services are unstable over NFS. Those need their own local solution and need to be kept separated. I only ran into a few of these.</li>
<li class="">Some container services are inherently bloated (Example: YouTrack) or churn through CPU running schedule tasks (Example: UrBackup and Syncthing). Isolate those to hosts that can handle the load without robbing resources from other important services during critical times.</li>
<li class="">Some services are too essential to run on a host with others, they need to be isolated. I always want to be able to reboot a host without it causing network issues with other hosts or killing my automation service. If something goes wrong during maintenance, I don't want that to snowball into a complete outage.</li>
</ul>
<p>Chasing the dream of an all-in-one home lab may never actually come to pass. I know I mentioned the possibility of Unraid fulfilling that for me. I will aim for that, but I don't think it will a 100%. I'm starting to feel like each piece of hardware I have represents a tribe with its own customs, rules, and traditions. When I become interested in setting up a new service, I need to sort out which tribe it will belong to. The rest is easy.</p>
<p>The better question becomes: How can I limit the amount of tribes (physical hosts) while still accommodating for all the individual quirks that each of my services have. They all require a home, after all. I expect that is what I will be thinking about the most as I continue with this hobby as I go into the future.</p>]]></content>
        <author>
            <name>Eric Post</name>
            <uri>https://linkedin.com/in/erickpost</uri>
        </author>
        <category label="Self-Hosting" term="Self-Hosting"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[What I'm Hosting Right Now?]]></title>
        <id>https://ekioga.github.io/docusaurus-blog/blog/what-im-hosting-right-now</id>
        <link href="https://ekioga.github.io/docusaurus-blog/blog/what-im-hosting-right-now"/>
        <updated>2025-09-13T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[A few years back, my wife and I decided to start messing around with game design as a hobby. My brain immediately time traveled to a future where we're working with contractors and publishers as a business entity.]]></summary>
        <content type="html"><![CDATA[<p>A few years back, my wife and I decided to start messing around with game design as a hobby. My brain immediately time traveled to a future where we're working with contractors and publishers as a business entity.</p>
<p>A bit early for that? Absolutely. In response, I'll posit this: It's never too early to build out our studio's IT infrastructure! I then run off with my binder and pocket protector.</p>
<p>I am a huge fan of workflows and tooling. Having a large practical problem like this to solve is a fun as eating ice cream. It's a long post, so please skip around.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="table-of-contents">Table of Contents<a href="https://ekioga.github.io/docusaurus-blog/blog/what-im-hosting-right-now#table-of-contents" class="hash-link" aria-label="Direct link to Table of Contents" title="Direct link to Table of Contents" translate="no">​</a></h2>
<ul>
<li class=""><a href="https://eric-post.com/what-im-hosting-right-now/#network-apps" target="_blank" rel="noopener noreferrer" class="">Networking Apps</a></li>
<li class=""><a href="https://eric-post.com/what-im-hosting-right-now/#identity-access" target="_blank" rel="noopener noreferrer" class="">Identity Access</a></li>
<li class=""><a href="https://eric-post.com/what-im-hosting-right-now/#monitoring" target="_blank" rel="noopener noreferrer" class="">Monitoring</a></li>
<li class=""><a href="https://eric-post.com/what-im-hosting-right-now/#notifications" target="_blank" rel="noopener noreferrer" class="">Notifications</a></li>
<li class=""><a href="https://eric-post.com/what-im-hosting-right-now/#ai" target="_blank" rel="noopener noreferrer" class="">AI</a></li>
<li class=""><a href="https://eric-post.com/what-im-hosting-right-now/#container-management" target="_blank" rel="noopener noreferrer" class="">Container Management</a></li>
<li class=""><a href="https://eric-post.com/what-im-hosting-right-now/#update-management" target="_blank" rel="noopener noreferrer" class="">Update Management</a></li>
<li class=""><a href="https://eric-post.com/what-im-hosting-right-now/#documentation" target="_blank" rel="noopener noreferrer" class="">Documentation</a></li>
<li class=""><a href="https://eric-post.com/what-im-hosting-right-now/#backup-disaster-recovery" target="_blank" rel="noopener noreferrer" class="">Backup &amp; Disaster Recovery</a></li>
<li class=""><a href="https://eric-post.com/what-im-hosting-right-now/#security" target="_blank" rel="noopener noreferrer" class="">Security</a></li>
<li class=""><a href="https://eric-post.com/what-im-hosting-right-now/#end-user-support" target="_blank" rel="noopener noreferrer" class="">End-user Support</a></li>
<li class=""><a href="https://eric-post.com/what-im-hosting-right-now/#productivity-services" target="_blank" rel="noopener noreferrer" class="">Productivity Services</a></li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="network-apps">Network Apps<a href="https://ekioga.github.io/docusaurus-blog/blog/what-im-hosting-right-now#network-apps" class="hash-link" aria-label="Direct link to Network Apps" title="Direct link to Network Apps" translate="no">​</a></h2>
<ul>
<li class="">Nginx Proxy Manager<!-- -->
<ul>
<li class="">My reverse Proxy</li>
<li class="">Bought a domain (eric-post.com) and pulled its cert using this tool. This, in conjunction with DNS rewriting, allowed me to put HTTPS in front of my internal home services.</li>
</ul>
</li>
<li class="">AdGuard Home<!-- -->
<ul>
<li class="">My internal DNS</li>
<li class="">I used PiHole for about a decade before moving over to AdGuard Home. I felt that the ad blocking performance and efficacy was about the same between the two.</li>
<li class="">What got me to finally switch over was the AdGuard's ability create DNS rewrites. At first, I used this to make internal domain names based off of cat puns. Much better to give my wife a URL to bookmark once, instead of telling her new IPs each time I swapped services to other hosts. However, this became 100% critical once I introduced Nginx Proxy Manager.</li>
</ul>
</li>
<li class="">Cloudflare DNS &amp; Zero Trust Netoworking<!-- -->
<ul>
<li class="">My external DNS</li>
<li class="">I rely on Cloudflare as my eternal DNS provider for eric-post.com because their 'Zero Trust' network access tool lets me securely expose my internal services. Oh yeah, it's also free!<!-- -->
<ul>
<li class="">I self-host their 'Cloudflared' container which creates a private network tunnel between Cloudflare and whatever internal service I point it at. (I love tunnels because I don't have to open ports on my end.) I then created a network application on the Cloudflare end that put's my exposed service behind an MFA prompt.<!-- -->
<ul>
<li class="">In order to access the login page for my exposed service outside my network, you need to already have your email address included in the ACLs within Cloudflare. Then you need to be able to check that email to gain the codes you need to proceed. Not bad!</li>
</ul>
</li>
<li class="">If at some point, I stop trusting Cloudflare's zero trust solution, I'll move onto Pangolin, a comparable open source solution.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="identity-access">Identity Access<a href="https://ekioga.github.io/docusaurus-blog/blog/what-im-hosting-right-now#identity-access" class="hash-link" aria-label="Direct link to Identity Access" title="Direct link to Identity Access" translate="no">​</a></h2>
<ul>
<li class="">Pocket-ID<!-- -->
<ul>
<li class="">My private SSO Provider that provides OIDC authentication.</li>
<li class="">This is a super light weight and focuses on passing tokens instead of passwords.</li>
<li class="">Not all my services are compatible with OIDC yet. For those, I still rely 1password to get by.</li>
<li class="">I may add Authentik at some point if I end up with more users than just my wife, only because it supports every other authentication solution, and should cover almost all of my services. It's also been audited by independent security firms. However, it's bloated and 97% of its features are overkill for my use cases.<!-- -->
<ul>
<li class="">I am sticking with Pocket-ID for now, holding out hope that OIDC support in the FOSS community continues to grow.</li>
<li class="">If I suddenly need to onboard other apps using Pocket-ID OIDC tokens that aren't compatible, I believe I know better option than Authentik.<!-- -->
<ul>
<li class="">I would try to use the "oauth2-proxy" container service to do the translation with non-OIDC compatible services. I had this setup once but never really needed it, so I spun down the service. However, if security audits get involved, I'll probably have to come crawling over to Authentik instead to make sure I'm covered.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="monitoring">Monitoring<a href="https://ekioga.github.io/docusaurus-blog/blog/what-im-hosting-right-now#monitoring" class="hash-link" aria-label="Direct link to Monitoring" title="Direct link to Monitoring" translate="no">​</a></h2>
<ul>
<li class="">
<p>Beszel</p>
<ul>
<li class="">Simple host and container performance monitoring.</li>
</ul>
</li>
<li class="">
<p>It's agent can be installed on the host itself, or ran in a container. I love this flexibility.</p>
</li>
<li class="">
<p>Uptime Kuma</p>
<ul>
<li class="">Service up/down monitoring.</li>
<li class="">An open-source Swiss army knife for monitoring a ton of different services. Very useful when troubleshooting.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="notifications">Notifications<a href="https://ekioga.github.io/docusaurus-blog/blog/what-im-hosting-right-now#notifications" class="hash-link" aria-label="Direct link to Notifications" title="Direct link to Notifications" translate="no">​</a></h2>
<ul>
<li class="">Mailrise/Apprise/Pushover stack<!-- -->
<ul>
<li class="">Mailrise acts as an SMPT server that translates SMTP messages into something that Apprise can read.</li>
<li class="">Apprise is compatible with a ton of modern message protocols. It takes the translated email sent from Mailrise and sends it over to Pushover's API.</li>
<li class="">Pushover is a service that will send push notifications to your phone. I've been using its free tier for a long time without any troubles.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="ai">AI<a href="https://ekioga.github.io/docusaurus-blog/blog/what-im-hosting-right-now#ai" class="hash-link" aria-label="Direct link to AI" title="Direct link to AI" translate="no">​</a></h2>
<p>Because it's 2025, and everybody should have their own private AI tools.</p>
<ul>
<li class="">
<p>LiteLLM</p>
<ul>
<li class="">Connects all LLM models together into one API.<!-- -->
<ul>
<li class="">External Models (With super cheap API pricing!)</li>
</ul>
</li>
</ul>
</li>
<li class="">
<p>Grok</p>
</li>
<li class="">
<p>Chat-GPT</p>
</li>
<li class="">
<p>Anthropic</p>
</li>
<li class="">
<p>Local Models</p>
<ul>
<li class="">Llama</li>
<li class="">gpt-oss</li>
<li class="">Gemma</li>
<li class="">Deepseek</li>
</ul>
</li>
<li class="">
<p>Comfy UI</p>
<ul>
<li class="">Used for generating images from text prompts to kick-start creativity and inspiration.</li>
</ul>
</li>
<li class="">
<p>Open WebUI</p>
<ul>
<li class="">Gives me an easy chat interface like chat-gpt.</li>
<li class="">Connects with LiteLLM, which in turn connects it to all the LLMs above.</li>
</ul>
</li>
<li class="">
<p>MAESTRO</p>
<ul>
<li class="">Geared towards time intensive research. Give it a topic, a series of questions to answer, how long you want it to spend, and it will get to work searching the internet for you. It will spawn a bunch of individual web search agents, then compile all their notes onto one page. Then it will take those notes and compile it into a fancy report for you.</li>
<li class="">SearXNG - This is a private self-hosted search engine. It can be used like Google and all that, but I honestly just have this running for MAESTRO.<!-- -->
<ul>
<li class="">You can pay for API tokens from a service like LinkUP. Or, you can be like me and just point MAESTRO at your local SearXNG instance and enjoy free automated web searching.</li>
</ul>
</li>
</ul>
</li>
<li class="">
<p>Home Assistant</p>
<ul>
<li class="">I replaced my Alexa and Google Home devices with the voice assistant feature that comes with Home Assistant. In addition to the typical home automation fair, you can ask my local LLMs a question using your voice.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="container-management">Container Management<a href="https://ekioga.github.io/docusaurus-blog/blog/what-im-hosting-right-now#container-management" class="hash-link" aria-label="Direct link to Container Management" title="Direct link to Container Management" translate="no">​</a></h2>
<ul>
<li class="">GitHub (The exception!)<!-- -->
<ul>
<li class="">My source of truth for all my container's docker compose files and other scripts.</li>
<li class="">I used a Gitea instance for years, but I outgrew it when I began playing around with mend renovate and becoming envious of Github/Gitlab pages.</li>
<li class="">I moved over to hosting my own GitLab instance (using runners for CI/CD automation) for a while before settling with GitHub. It's become too important as a core service and I no longer trust myself to self-host it more securely than how GitHub already does.</li>
</ul>
</li>
</ul>
<blockquote>
<p>"It's a relief knowing that I'm no longer self-hosting my source of truth for my self-hosted service." Eric Post, right to your face.</p>
</blockquote>
<ul>
<li class="">Komdo<!-- -->
<ul>
<li class="">Docker container orchestration</li>
<li class="">I used Portainer for a few years before moving over to this Komodo earlier this year. If I ever went back to hosting an HA docker swarm cluster, I can easily see myself moving back to Portainer.</li>
<li class="">Komodo was a bit tougher to set up, but I love how it's work flow is centered around remote Git repositories and lets me easily point my stacks (compose files) at other servers on the fly. Perfect for how often I tend to move services around.</li>
<li class="">These days, I primarily use it to manage containers located on a special container VM I have set up on Unraid. These are for services that I have not migrated over to either Unraid or Home Assistant yet. Or, for the few services begrudgingly located on my Synology's NAS's for whatever reason.</li>
<li class="">I played around with Kubernetes using Talos Linux and Lens about a year ago. I dropped all that when I realized how much time I'll be spending converting services over. Learning about helm files gave me hope on getting back into Kubernetes once again if my services actually become important.</li>
</ul>
</li>
<li class="">Unraid<!-- -->
<ul>
<li class="">Focused on GPU and heavy CPU container workloads.</li>
<li class="">I have an old gaming machine with top end hardware for the 2020 era, i7 with a GeForce 2080 Super . I replaced it with a new one this year and wasn't sure what to do with it. Slapping Unraid on it elevated it to being my favorite server in my home. It's so easy to use that even my wife is fine logging into it and managing our game servers.<!-- -->
<ul>
<li class="">I came up with an odd use case where I wanted the video card HDMI output to pipe video from a Pop!_OS VM. I wanted it to be my VM for all my GPU related work flows and containers while also being the family media PC connected to my living room TV. I thought that was just a bridge to far until I learned about Unraid. I gave it a shot, and it did all that I wanted and more! I liked it so much I bought the lifetime license within a week of the trial. I might go on and on about how great Unraid is in another post at some point.<!-- -->
<ul>
<li class="">I would be lying if I said I kept that setup going for too long. As impressive as Unraid's flexibility was, the GPU workloads were just bogged down too much by all the layers of translation between the VM and the GPU hardware itself. It worked, but not practically speaking. I now run all my VM workloads directly on Unraid itself via it's apps, and it's fantastic. I had to dump the Pop!<em>OS VM and just use an old laptop as my media PC (with it running Pop!_OS because I grew to love it)</em>.</li>
</ul>
</li>
</ul>
</li>
<li class="">It's replaced my old ProxMox hypervisor server. Unraid now runs my VM work loads. As of now, this is just a single small docker container VM. I am trying to keep my VM count as low as possible. I'm trying to move away from that maintenance as much as possible</li>
<li class="">Web GUI so easy and the heavy technical stuff has been abstracted away behind apps (containers) and plugins (linux tools, services, and drivers). Installing apps and plugins is as easy as browsing through the included app store.<!-- -->
<ul>
<li class="">It also supports typical docker compose files and can be managed like these "apps". You can even install a container manager agent for something like Portainer and Komodo and manage all these "apps" remotely if you prefer that instead. I did for quite a while.</li>
<li class="">At first, the user-friendliness felt restrictive. However, once I realized how easy it was to turn my wife into her own system admin with just a few clicks had me thinking that I had an answer to an old question. If I got obliterated by a buss, how will she manage the services I maintain that she's come to rely on? I think focusing on migrating as much as I can to Unraid will be the best solution to this for now. I'm about 60-70% there already.</li>
</ul>
</li>
<li class="">Home Assistant Add-Ons<!-- -->
<ul>
<li class="">Similar to Unraid, add-on for home assistant are just curated containers from their built-in app store.<!-- -->
<ul>
<li class="">At first, this app store feels a bit too small to fit many use cases. However, once I set up HACS (a custom add-on repo) my options opened up immensely.<!-- -->
<ul>
<li class="">I use this to host many containers like my primary DNS (AdGuard), ZigBee2MGTT, Nginx Proxy Manager and much more. I trust Home Assistant because the folks behind the project seem to know what they are doing.</li>
<li class="">I've accidentally broke the OS catastrophically by poking around under the hood where I should have more than a few times. Any other OS when of kernel panicked. Yet, Home assistant OS keeps scanning for my mistakes and fixing itself upon reboot each time.</li>
</ul>
</li>
<li class="">Just like Unraid, my wife is already logging into turn things on and off occasionally, so when I kick the bucket, she can easily keep it updated, add new apps, and trucking along for as long as she wants. For very light CPU only workloads, I try to put them on this server first.</li>
</ul>
</li>
</ul>
</li>
<li class="">Synology NAS<!-- -->
<ul>
<li class="">Not a fan of how perpetually out of date their docker container app is. It's also easy to outgrow the GUI within just a few hours of learning docker compose. However, it works great when used in conjunction with a container manager like Komodo or Portainer. Just install a Komodo agent on there, then you can manage the stack remotely.</li>
<li class="">Not a fan of the 2x VM license limit.</li>
<li class="">Perfect for container based workloads focusing on managing data on the NAS directly.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="update-management">Update Management<a href="https://ekioga.github.io/docusaurus-blog/blog/what-im-hosting-right-now#update-management" class="hash-link" aria-label="Direct link to Update Management" title="Direct link to Update Management" translate="no">​</a></h2>
<ul>
<li class="">
<p>Containers</p>
<ul>
<li class="">Komodo<!-- -->
<ul>
<li class="">Komodo is most likely the worst answer to most. I say that because it's auto update features, albeit totally functional, doesn't give you any control as to when it performs the container update. It does support push notifications which goes far into at least letting me know what's going on as it happens.</li>
<li class="">Not great, but my backups are resilient enough to where I'd rather just get the latest security updates and live recklessly.</li>
</ul>
</li>
</ul>
</li>
<li class="">
<p>Unraid</p>
<ul>
<li class="">App and plugin updates are managed through an auto-backup job that runs each night at a set time. Much more manageable to Komodo's update jump scares.</li>
</ul>
</li>
<li class="">
<p>Home Assistant</p>
<ul>
<li class="">Most of the services on this host are way too important to auto-update on their own. I have it set to let me know when updates are ready in the GUI. I check once a week, click a button and do the needful in a controlled manner.</li>
</ul>
</li>
<li class="">
<p>VM Hosts</p>
<ul>
<li class="">Ansible<!-- -->
<ul>
<li class="">I have playbooks that run package manager updates at a set time every night. They're configured to send push notifications when a host needs a reboot.</li>
<li class="">I hate having to remember to maintain bare-metal and VM hosts. I try to minimize their presence in my home as much as possible. Ansible is there to make sure that basic routine maintenance doesn't slip by for the ones I begrudgingly have running.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Other hosts like bare metal Unraid or my Synology NAS's send me push notifications when a new update is ready. I review them and get them installed during weekends. Way too critical for anything automatic.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="documentation">Documentation<a href="https://ekioga.github.io/docusaurus-blog/blog/what-im-hosting-right-now#documentation" class="hash-link" aria-label="Direct link to Documentation" title="Direct link to Documentation" translate="no">​</a></h2>
<ul>
<li class="">Blinko<!-- -->
<ul>
<li class="">Used for quick notes I need to take down on my smartphone when I am out and about. When I get home, I move these notes over to one of the services listed below. Exposed using Cloudflare zero trust.</li>
</ul>
</li>
<li class="">TrilliumNext<!-- -->
<ul>
<li class="">I have a separate instance for my wife and I. Best used for when a hierarchical note style is needed.</li>
</ul>
</li>
<li class="">Bookstack<!-- -->
<ul>
<li class="">This is used as our main knowledge base for just about everything. It's organized like a physical library. You have bookshelves that contain individual books and those each have their own chapters and pages. Very intuitive architecture.</li>
</ul>
</li>
<li class="">YouTrack<!-- -->
<ul>
<li class="">My favorite project management tool. It has all the project tools you can ask for in one location.</li>
<li class="">It's a commercial tool created by JetBrains. It's free and self-hostable if you have less than 10 users.</li>
<li class="">Just like home assistant, it backs itself up as a zip file every night and copies that zip file over to my NAS. It stores only 30 days worth of backups. Those are shipped out to Switzerland nightly.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="backup--disaster-recovery">Backup &amp; Disaster Recovery<a href="https://ekioga.github.io/docusaurus-blog/blog/what-im-hosting-right-now#backup--disaster-recovery" class="hash-link" aria-label="Direct link to Backup &amp; Disaster Recovery" title="Direct link to Backup &amp; Disaster Recovery" translate="no">​</a></h2>
<p>Asset Drive</p>
<ul>
<li class="">
<p>iSCSI/Syncthing/ProtoDrive stack. Automated local and offsite backups syncing.</p>
</li>
<li class="">
<p>I am a little proud of this asset drive solution I came up with. I think of it like a data conveyor belt that automatically syncs backups and ships them out to Switzerland.</p>
<ul>
<li class="">It starts off as 2x iSCSI shares connected to both our PCs. Both are stored on my NAS's raid.</li>
</ul>
</li>
<li class="">
<p>I have a Syncthing agent installed on both PCs. Allowing the Syncthing container running on my NAS to sync all the data in the asset folder every minute over to the iSCSI drives attached to each of our PCs. This gives the asset drive the feeling like it's a shared Dropbox that you can execute applications on directly. It's as resilient as it is collaborative.</p>
</li>
<li class="">
<p>On my PC, I have my Proton Drive installed and pointed to the asset drive, along with another backup drive. All changes that get synced to those drives get synced out to my off site backup location at the same time. Located in the EU using the Proton Drive service.</p>
</li>
<li class="">
<p>It's easy to tell my wife that anything she really cares about can just be dragged and dropped onto this asset drive, and she can then safly forget about it.</p>
</li>
</ul>
<p>Paperless-NGX</p>
<ul>
<li class="">Automatically places important physical documents that I scan with my phone into a single location on my NAS's asset drive location. It then allows me to search and tag them within the interface. There is a folder on my iSCSI asset drive that I can drag and drop files into and have it automatically be ingested into Paperless-NGX. All gets shipped out to Switzerland.</li>
<li class="">I also have this connected to Paperless-AI and Paperless-GPT so that my local LLMs can interact with these documents.</li>
</ul>
<p>NAS</p>
<ul>
<li class="">NFS Mounts<!-- -->
<ul>
<li class="">Used originally to host my exposed docker volumes across the network. This worked fine but ran into odd issues with containers that relied on a database. I had to move those services around to different hosts until I realized that pattern. I looked it up and found out that what I was doing was dumb. I later learned to minimize my use of NFS.</li>
<li class="">Used primarily has a method to ship backups from host to NAS.</li>
</ul>
</li>
<li class="">iSCSI<!-- -->
<ul>
<li class="">Desktop PC Drives<!-- -->
<ul>
<li class="">Asset Drive</li>
<li class="">Proton Backup Drive</li>
</ul>
</li>
</ul>
</li>
<li class="">Windows Shares<!-- -->
<ul>
<li class="">The original network shares I set up about a decade ago, with data going back to when I was a child in the 90s. Not used as much since I implemented the iSCSI drives.</li>
</ul>
</li>
</ul>
<p>Containers Volumes</p>
<ul>
<li class="">
<p>Komodo</p>
<ul>
<li class="">Nautical Container Backup Service<!-- -->
<ul>
<li class="">Every night at a set time, Nautical stops all the other running containers on the host, copies all the volume data to a backup file share on my NAS across my network using an NFS mount.</li>
<li class="">This NFS backup file share is synced to my PC's Proton Backup Drive iSCSI drive using Syncthing. The installed Proton Drive application on my PC then syncs all this backup data out to Switzerland.</li>
<li class="">This ensures that I always have the last nights backups available in raw form. Allowing me to quickly revert and fix any containers that I break or blow up from a bad update.</li>
</ul>
</li>
</ul>
</li>
<li class="">
<p>Home Assistant</p>
<ul>
<li class="">It's super easy to configure it to back up itself and it's apps into a super easy zip file then drop it on a remote file share. I have it set to do this every night and delete any backups older than 30 days.</li>
</ul>
</li>
<li class="">
<p>Unraid</p>
<ul>
<li class="">Appdata Backup Plugin<!-- -->
<ul>
<li class="">Appdata is where all the container volumes are stored by default.</li>
<li class="">Just like Nautical, this plugin stops all running containers each night, copies all their volume data over to the backup share on the Synology NAS over an NFS mount. This backup share is synced out to Switzerland. Finally, it runs the containers again, pulling in its latest updates.</li>
</ul>
</li>
<li class="">Duplicati<!-- -->
<ul>
<li class="">Runs as container located on the container VM (hosted on unraid)</li>
<li class="">This service takes the copied files from the Nautical backup job described above, encrypts them and applies a "Smart backup retention" backup policy. Then it places those encrypted files in a separate directory in the same backup shared on the NAS.<!-- -->
<ul>
<li class="">What is smart backup retention? For Duplicati, it means this: There will remain one backup for each of the last 7 days, each of the last 4 weeks, each of the last 12 months. There will always be at least one remaining backup.</li>
</ul>
</li>
<li class="">The Duplicati NFS file share is also synced to my Proton Backup Drive using syncthing and shipped out to Switzerland.</li>
</ul>
</li>
</ul>
</li>
<li class="">
<p>UrBackup</p>
<ul>
<li class="">My wife's old gaming PC turned into a Fallout 4 only computer. She spent so much time in reinventing the world like an environmental artist using hundreds of mods over 7 years.<!-- -->
<ul>
<li class="">Her gaming PC had to be enshrined as it was back in 2018. Still near her desk but only connected with a network cable so she can remotely play with moonlight/sunshine. Her thousands of hours spent on her save file meant that getting a backup solution for her became very important.</li>
</ul>
</li>
<li class="">UrBackup runs a full image backup once a month, and then incremental image backups every 2 days and store those files on the NAS.<!-- -->
<ul>
<li class="">These backups have been tested in VMs, and I was able to install her PC image on her steam deck and her fallout 4 save worked! UrBackup is a perfect file backup and network image solution.</li>
</ul>
</li>
<li class="">It's running on my Unraid server because it can use a lot of CPU while running its remote image backups. What would take up 80% of my Raspberry Pi 5 or on my NAS would only use about 10% cpu on my Unraid server's i7. Much better tradeoff.</li>
<li class="">This backup does not go to Switzerland. I'm too cheap to pay for that much storage right now.</li>
</ul>
</li>
</ul>
<p>UPS</p>
<ul>
<li class="">I own 3x UPS's.<!-- -->
<ul>
<li class="">UPS 1: Powers all my network gear and a few Raspberry Pi's.<!-- -->
<ul>
<li class="">I heavily rely on PoE to keep the all the networking gear across my entire home efficiently powered and protected. I find that having all your network gear on a single UPS can keep my entire network going chugging along for an hour or so. If I plug in anything else, I suddenly only have 8 minutes.</li>
</ul>
</li>
<li class="">UPS 2: Powers my Unraid server and a few Raspberry Pi's.<!-- -->
<ul>
<li class="">Installed the NUT (Network UPS Tools) plugin that could connect to my UPS over USB. It sends me push notifications when it detects power up/down events. It's also configured to gracefully shutdown VMs and containers if power isn't restored within 5 minutes. This covers about all of my important services. I really, really love this!</li>
<li class="">I tried many times to manage my UPS with NUT with just the Linux command line. I could never get it to fully work. Meanwhile with Unraid, just download the plugin using the GUI, and it works great out the box with its own dashboard widgets.</li>
</ul>
</li>
<li class="">UPS 3: Powers our desktop PCs. Gives us about 10 minutes quite our games and shut down out computers.</li>
</ul>
</li>
</ul>
<p>DNS Failover</p>
<ul>
<li class="">AdGuard Home Sync<!-- -->
<ul>
<li class="">This service syncs the configurations once an hour between my primary DNS server and secondary DNS server.</li>
<li class="">I initially ran an HA cluster with failover, but after learning about AdGuard Home Sync, I realized this container provides the same redundancy without all the hassle that comes with cluster maintenance.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="security">Security<a href="https://ekioga.github.io/docusaurus-blog/blog/what-im-hosting-right-now#security" class="hash-link" aria-label="Direct link to Security" title="Direct link to Security" translate="no">​</a></h2>
<p>KASM</p>
<ul>
<li class="">Web app running my Unraid (because of the GPU support) server that allows you to spin up temporary containers, from a full OS or just a single app like a web browser. You can download full operating systems and applications from the app store and get something up and running in seconds, then destroy it a minute later.</li>
<li class="">Tools appear when I need them and go away when you don't. No need to maintain VMs. Perfect for using tools that you only need every once in a while.</li>
<li class="">It's my #1 tool for:<!-- -->
<ul>
<li class="">Running stuff found in Kali Linux or Parrot OS.</li>
<li class="">Opening up browser containers to detonate links.</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="end-user-support">End-User Support<a href="https://ekioga.github.io/docusaurus-blog/blog/what-im-hosting-right-now#end-user-support" class="hash-link" aria-label="Direct link to End-User Support" title="Direct link to End-User Support" translate="no">​</a></h2>
<ul>
<li class="">RustDesk<!-- -->
<ul>
<li class="">Feels like an open source TeamViewer.</li>
<li class="">I host a RustDesk container server that allows designated clients can connect to.</li>
<li class="">I have Raspberry Pi running at my Mom's house that is connected to its own restricted vLan in my home network using tailscale. I have this vLan connected to this RustDesk server. Meaning I can help my mom over the phone and gain remote access using all my own tools as if they were in the same network. Very nice!</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="productivity-services">Productivity services<a href="https://ekioga.github.io/docusaurus-blog/blog/what-im-hosting-right-now#productivity-services" class="hash-link" aria-label="Direct link to Productivity services" title="Direct link to Productivity services" translate="no">​</a></h2>
<ul>
<li class="">The typical boring media PC related stuff that most people commonly self-host.</li>
<li class="">Navidrome<!-- -->
<ul>
<li class="">I'm a child of the MP3 90s. I never got into streaming platforms. I buy mp3's from Bandcamp and stream them to my devices using Navidrome.</li>
</ul>
</li>
<li class="">Drawpile server<!-- -->
<ul>
<li class="">Open source multiplayer photoshop-like application. Great for collaborative mood boards and stuff like that.</li>
</ul>
</li>
<li class="">LanguageTool<!-- -->
<ul>
<li class="">It's your own free private self-hosted open source Grammarly!</li>
</ul>
</li>
<li class="">Mealie<!-- -->
<ul>
<li class="">Recipe and shopping list. Exposed using Cloudflare zero trust so I can access on my phone at the grocery store.</li>
</ul>
</li>
<li class="">DumbSuite - Very singularly focused web apps.<!-- -->
<ul>
<li class="">Dumb Do<!-- -->
<ul>
<li class="">Basic to-do list</li>
</ul>
</li>
<li class="">Dumb Pad<!-- -->
<ul>
<li class="">Basic scratch pad</li>
</ul>
</li>
<li class="">Dumb Kan<!-- -->
<ul>
<li class="">Basic KanBan Board.</li>
</ul>
</li>
<li class="">Dumb Budget<!-- -->
<ul>
<li class="">Basic budgeting app.</li>
</ul>
</li>
</ul>
</li>
<li class="">Haus<!-- -->
<ul>
<li class="">Perfect little suite of productive side tools. I primarily use it for mixing ambient sounds to help me focus.</li>
</ul>
</li>
<li class="">Ghost<!-- -->
<ul>
<li class="">It's the blog thing you're looking at right now. Based off an old WordPress add-on, I believe.</li>
<li class="">I don't know if I really recommend it. It's very simple, straight forward and not a lot of fun for tinkers like me. But, it's out-of-the box nature does force me to actually focus on writing. I hate how effective that has been for me.</li>
</ul>
</li>
<li class="">Wallos:<!-- -->
<ul>
<li class="">Service to keep track of our active monthly and yearly subscriptions. Tied to push notifications that alert when specified services are about to renew.</li>
<li class="">I really need to take the time to set this up properly. It's one of those things that feels important but too boring to really dig into.</li>
</ul>
</li>
<li class="">IT-Tools<!-- -->
<ul>
<li class="">Swiss-army knife of free random system admin tools.</li>
<li class="">There are better, more complete solutions like this out there. I just haven't spent the time playing with them yet.</li>
</ul>
</li>
<li class="">Home Intranet<!-- -->
<ul>
<li class="">Homepage<!-- -->
<ul>
<li class="">Yaml based homepage tool. I've added custom widgets like stock tickers, search bars and integration like home assistant automation, and much more. Ton's of API compatibility with lots of popular self-hosted tools</li>
<li class="">I placed all my end-user facing applications and AI services here.</li>
</ul>
</li>
<li class="">Organizr<!-- -->
<ul>
<li class="">Fantastic services that wrap a website around a very customizable roll-out frames that give you access to more bookmarks. I added all my system admin bookmarks here.</li>
<li class="">I have this pointed to my homepage service by default, allowing me to see both user and admin world simultaneously. It's worked so well for me and my routine that I haven't used my browser's bookmarks for several months now. I never thought I'd be a "homepage" guy, but using both homepage and organizr in conjunction with each other is a perfect solution for having admin and user scopes isolated, yet available.</li>
<li class="">Big downside: Maintainer disappeared 3 years ago and this service apparently wasn't popular enough for any forks to appear. Very, very depressing. It still works, but it's a bit janky, and I am sad for the day it becomes a too much of a liability.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>I have a few more services bouncing around, but I want to end this here. I now realize just how much work I have put into this stuff over the past few years. Wow!</p>]]></content>
        <author>
            <name>Eric Post</name>
            <uri>https://linkedin.com/in/erickpost</uri>
        </author>
        <category label="Self-Hosting" term="Self-Hosting"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Why do this at home?]]></title>
        <id>https://ekioga.github.io/docusaurus-blog/blog/why-do-this-at-home</id>
        <link href="https://ekioga.github.io/docusaurus-blog/blog/why-do-this-at-home"/>
        <updated>2025-08-06T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[For years, I thought the best IT workers were the ones who went home to do more IT for themselves. I was wrong!]]></summary>
        <content type="html"><![CDATA[<p>For years, I thought the best IT workers were the ones who went home to do more IT for themselves. I was wrong!</p>
<p>I'm a senior system admin in my current role as of this writing. Still working through the imposter syndrome that comes with the word 'senior'. It's true, I've spoken to a few colleagues over the years and was surprised that I'm mostly alone in this self-hosting stuff. Many did when they first got into IT, but that tapered off as they became more comfortable in their career. Those that continued to do so keep it very simple. Mostly maintaining a pi-hole somewhere at home then leave it at that. That was me for years. I totally get it. Very reasonable.</p>
<p>When you spend all day staring at a screen, working through a cavalcade of one crisis after another, it's understandable why we'd want to wrap this stuff up by 5pm. This is key. Go fishing. Play with the kids. Argue with the neighbor through the fence. Whatever familiar coping mechanism that is the opposite of what you just dealt with all day.</p>
<p>That ain't me. I still find a lot of this computer stuff way too fascinating after all these years, even the mundane stuff we all take for granted. The thrill I got in '96 when my 11-year-old self saw 4 computers connected to the same Quake 2 server over LAN at a friends house, in person, left me in tears of joy. My local only N64, with it's split screen multiplayer became a joke. I found my new home. That's me!</p>
<p>Seeing all that tech working for the both of us to make something magical happen like that was overwhelming. I became addicted to solving problems in service of this magic. Not magic in a wizard sense. This was more like telekinesis they call tcp/ip. It's magic adjacent but real. And humans made this? Wild! Stuff like that. When I finally get something to work correctly, I still get a little taste of that feeling to this day.</p>
<blockquote>
<p>"You can do your shopping at home or play Mortal Kombat with a friend in Vietnam." -Chip Douglas, The Cable Guy</p>
</blockquote>
<p>I'm a kid from the sticks miles from any social life. Summer vacation meant feeling stuck as a mud person in the forest. The wonder of near instant communication between points in space is big part of that wonder, as you can imagine, but not the whole story.</p>
<p>I love self-hosting because I love the control that comes with it. I do it for myself to match my own sensibilities. There aren't any directors or VPs that need to be convinced. No worries about deadlines piling up as my tasks grow logarithmically. No concern about what will happen when I hand it off to others. I don't have thousands of users to worry about. Waking up suddenly at 2am because of a sudden "sense" that I made a mistake somewhere that I can't see because I missed it.</p>
<p>Those anxieties are what occupy my mind most of my waking life, unfortunately. It comes with the IT ops territory. This 24/7 on call work is always hurdling me towards burnout. That's the nature of it. The work related alerts on my phone bring me dread. My own personal network alerts on my phone, on the other hand, even when they tell me that all my stuff is on fire, still bring a kind of joy. Oh, look! Something needs to be tinkered with! A bit of mental balance. This is me!</p>
<p>The stakes are deliriously low at home. I can breathe while working on my own stuff. Small whiffs of magic as I make it a tiny bit better most of the time.</p>
<p>I need my linux/container world at home to balance out my windows/vm world at work. One feeds me but leaves me anxious, while the other treats me nice but hasn't ever paid me. It's not perfect, but it works as well as it needs to.</p>
<p>As you can probably tell by now, self-hosting is a kind of therapeutic hobby for me. It helps manage work burnout by reminding me that at least some of this can still be fun. I've needed that reminder several times over the past 5 years alone. Whether I am finding joy at home or not with my own stuff has shown to be a good barometer for my own mental health.</p>
<p>No matter how well I think I designed my home systems, It's all about using my imagination and playing in the sandbox at the end of the day. Stakes are very low. My wife is my only user, and she just wants the internet to work with as little advertisements as possible and the homepage I made to show her stocks. I'm in alignment with this directive. Deal!</p>]]></content>
        <author>
            <name>Eric Post</name>
            <uri>https://linkedin.com/in/erickpost</uri>
        </author>
        <category label="Self-Hosting" term="Self-Hosting"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[My Home Network]]></title>
        <id>https://ekioga.github.io/docusaurus-blog/blog/my-home-network</id>
        <link href="https://ekioga.github.io/docusaurus-blog/blog/my-home-network"/>
        <updated>2025-07-22T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Look at those circles and square! What the heck is a Zigbee!?]]></summary>
        <content type="html"><![CDATA[<p>Look at those circles and square! What the heck is a Zigbee!?</p>
<p>My home network has evolved rather little over the years. In fact, I've wasted a weekend not too long ago because I checked a box in some interface 8 to 10 years prior. So, this isn't me bragging. It's just a realization that I'm having. I just hit my 40s the other day. My stuff is old! I'm old!</p>
<p>The reason it's old, my network that is, is because I've used Unifi since I can remember. It's all I know now. Before that, I would just flash whatever consumer Netgear or Asus router I had on hand with open-wrt or tomato. I then spent a few years with PFsense/OPNsense on a dual nic atom Supermicro. As my interest in gaining more network control expanded, I moved onto hosting pfsense on a VM. I went deeper into the complexity. "Sorry, Babe. Your game server is down, and I still don't know why yet..."</p>
<p>The more I learned, the more I wanted an excuse to mess around. The more services I spun up, which consequently became important over time. And so the more complicated my home network became. I'm glad I slowed down to at least do some basic security here and there. Template something out, lock in auto updates and forgetting about it is not so bad right?</p>
<p>I figured it would be easier to implement security concepts as I went from the start instead of trying to retro-fit some kind of art piece that I would otherwise design.</p>
<p>I'm still not a networking guy. I just like to know exactly what I need to know to get to where I want to be. It's also true that I want to go in every direction by like 3 easy steps. No more, please. Let me hit that wall in just a few hours. I'll let my subconscious figure the rest out as a toss and turn in bed for a few nights. That'll make the hard part look easy.</p>
<p>One day at work, my boss unpacked a bunch of Unifi gear and wouldn't stop boasting about how cheap it was. "Sure, it's not CISCO," he said. "So it will never be business certified." I got the message. If you're a cheap shop like us, Unifi is a warm place to stay.</p>
<p>I ran home from my helpdesk job and bought one of those UFO shaped Unifi Wi-Fi pucks, a basic Unifi 8-port switch, and a searing Unifi gateway. Don't touch it! I then combined it all together using their cloud key software I hosted on a Raspberry Pi. I still think that's cool they let me do all that.</p>
<p>About 5 years later, around 2020, I replaced my cloud key and gateway with a UDM-PRO, added some security cameras around my Mt Rainier cabin and tossed a few PoE switches into the mix. It worked like magic! Nothing died! All my data was local!</p>
<p>As my network needs expanded over time, I would just go to the Unifi store and click some gizmo into my digital cart. I wouldn't even consider a 2nd opinion and smile about it the whole time. It would make it all the way to my rurally located mountain cabin and I would find a spot to plug it into a power outlet, and be almost done already. Unifi means I don't need to learn more than just a few things get to where I need to be today. That's been addicting so far. Maybe I am addicted to something about this.</p>
<p>Unifi is a walled garden. But, it's a relatively cheap walled garden. If you buy into the ecosystem wholesale, like I have apparently, it's just a matter of "plugging" things into things. Virtually and physically. Click a button to "adopt" the new doo-dad into in my local Unifi web gui to add it my your network. Watch as it pushes your configs to it, pulsates some pleasant LED glow, and now you move on. This walled garden has been cozy to me! Others have ghost stories with Unifi.</p>
<p>Apple users get it. I use Google stuff on my iPhone because I've lost it completely with all that stuff a while ago. I have no plan anymore. However, If I am allowed to have a high level of control in this walled garden, then I am all for it. I'll gladly stay inside if I don't feel hassled.</p>
<p>What are all these circles at the top about? I forgot.</p>
<p>I have 3 networks in total. Wifi, Wired and Zigbee.</p>
<ul>
<li class="">Wifi<!-- -->
<ul>
<li class="">Designed as a IoT no-mans land. It's where the monsters live.</li>
<li class="">Completely segmented away from the "Wired" network. Hosts on the wired network cannot communicate with hosts on the Wi-Fi network, and the other way around.</li>
<li class="">Truth is: I no longer host IoT devices on here. I still like the idea of treating my password secured Wi-Fi as if it was open internet. I could change that one day without worrying a lot, but I don't have to for now. So I will continue to pretend its lava.</li>
</ul>
</li>
<li class="">Wired<!-- -->
<ul>
<li class="">The gooey center!</li>
<li class="">This is where all the desktop gaming computers, servers, containers, and other types hosts live and do their stuff.</li>
</ul>
</li>
<li class="">Zigbee<!-- -->
<ul>
<li class="">My new home for all IoT devices.</li>
<li class="">Zigbee is its own separate network protocol that cannot talk to the internet, LAN, nor Wifi. A perfect location for privacy focused IoT devices!</li>
</ul>
</li>
</ul>
<p>I think it's the Zigbee part that might be the most interesting to me. The rest is just boring Unifi gear. Sorry I wrote so much about that.</p>
<p>So how did I make this "Zigbee" network happen?</p>
<p>I bought a ZigBee gateway coordinator (<a href="https://smlight.tech/product/slzb-06/?ref=eric-post.com" target="_blank" rel="noopener noreferrer" class="">SMLIGHT SLZB-06</a>) because of the YouTube algorithm back in May 2025. My IoT stuff was about 8 years old, and I began to wonder about them for a while already. Maybe it's good that I refresh some of that stuff. Then I found out about Zigbee and bought into another walled garden that promised full control of my local data. Deal! I plugged into one of my PoE connections and my&nbsp;<a href="https://www.home-assistant.io/?ref=eric-post.com" target="_blank" rel="noopener noreferrer" class="">Home Assistant</a>&nbsp;just picks it up right away! What's even better, Home Assistant manages its firmware updates, too! There are a lot of cheap ZigBee compatible devices on Amazon! All topics for later.</p>
<p>Oh Yeah, Home Assistant is my proxy host. That is what we were talking about. That square in the middle of the circles at the very top of this post. I forgot about that. It's running Nginx Proxy Manager as one of it's many plugins. Probably just containers but I like how it's not obvious to me.</p>
<p>This Raspberry Pi 5 running official Home Assistant OS sits in the middle of all 3 of these networks.</p>
<ul>
<li class="">It's associated with the ZegBee gateway by managing the ZegBee gateway coordinator over IP.<!-- -->
<ul>
<li class="">All my light bulbs and IR blasters can go nuts chattering to each other without me caring. No need to design a network box for them. They can go feral in their own obscure weird wireless protocol. That feels just fine at my current knowledge level.</li>
</ul>
</li>
<li class="">It's the only host on my wired network that is simultaneously connected to my wifi network. This is why I care about running Nginx Proxy Manager on this Home Assistant host. I can choose which wired services I want to expose to wifi over HTTPS using my personal domain certificates. Where you're looking now.</li>
</ul>
<p>I know that some folks would argue that I should be using Traefik instead of Nginx Proxy Manager. I'd fire back saying that I am just not smart enough for that yet.</p>
<p>Maybe it's because I just turned 40, but I am fine coasting on how this is working right now. Sure, there is a lot more I had to do to get make this far. I had to try and fail a few times and sit frustrated for a month or two. Like many things I've done, networking felt easy at first, and I thought I knew a lot. But I hadn't realized how much I took for granted this whole time.</p>
<p>Why would I care about this when I have been using that? Bumped into the concept of local DNS rewriting by accident that pieced it all together. My old tool didn't do that, so that meant I remained dumb about it. Not cool! I now get why my cloud flare idea failed. Just had to try to answer that question when looking at this weird new tool this one random day. Suddenly I became way more receptive to DNS topics after that. One thing led to another. Home Assistant became my Proxy Host.</p>
<p>It's now time for a breather. What does a few years of this look like? There is always more time to talk about this stuff later.</p>]]></content>
        <author>
            <name>Eric Post</name>
            <uri>https://linkedin.com/in/erickpost</uri>
        </author>
        <category label="Self-Hosting" term="Self-Hosting"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[eric-post.com is alive!]]></title>
        <id>https://ekioga.github.io/docusaurus-blog/blog/eric-post.com-is-alive</id>
        <link href="https://ekioga.github.io/docusaurus-blog/blog/eric-post.com-is-alive"/>
        <updated>2025-07-09T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[I did it! The proof is right here!]]></summary>
        <content type="html"><![CDATA[<p>I did it! The proof is right here!</p>
<p>Before you get too excited, this blog is about my hobbies. Stuff like self-hosting and game design. I know... I still think it needs a first post. It deserves it.</p>
<p>I consider my agile board one of my best friends. Each of my posts will be inspired by how I moved a task from left to right, gave up, or something else in between.</p>
<p>I meant to for this blog to be up and running over a year ago. In fact, it was one of my first projects since moving into my new apartment in Olympia, Washington back in late 2023. I knew I wanted to self-host it and wanted something dead simple. To talk about my self-hosting and game design journey as I go through it. Yet, I just couldn't get this task all the way to the right.</p>
<p>I first found ghost, but fell in love with Hugo. Hugo gave me the custom fonts I wanted and the LaTeX compatibility that made me feel fancy. I love markdown and enjoyed the workflows that Hugo offered me.</p>
<p>I then fell into a CI/CD pipeline rabbit hole that kept me treading water on the back-end automation that I couldn't quite get perfect. Constantly testing and tweaking the many workflows I put together. While my instance randomly crashes a few days later with zero errors. No problem, let's put Hugo on my self-hosted GitLab pages! Let's try it out in GitHub pages! Oh, cloud flare has static page hosting, too!</p>
<p>Never thinking about the content. Always testing and building. Can't write until the system is perfect! A year passed...</p>
<p>Once I finally finished all the testing I could think of, I was proud of what I made. Then it hit me. To use Hugo is to maintain a code base. Is that something I want to deal with in the future as this blog grows larger and larger? Nope. I dusted off Ghost and said I was sorry. Picked my theme and chose a stock font. Here it is. Done.</p>
<p>That's the story of how this first post got here. This first one was a doozy for me, but the rest should be easy. Hugo was an awful rabbit hole and I miss it. Ghost lets me just write content. I guess its down hill from here.</p>]]></content>
        <author>
            <name>Eric Post</name>
            <uri>https://linkedin.com/in/erickpost</uri>
        </author>
        <category label="News" term="News"/>
    </entry>
</feed>